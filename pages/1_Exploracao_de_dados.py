import streamlit as st
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ================================================
# 0. Configura√ß√£o e Fun√ß√µes de Cache
# ================================================

# Configura√ß√µes gerais do Streamlit
st.set_page_config(page_title='An√°lise e Predi√ß√£o de Umidade do Solo', layout='wide')

# Decorador para carregar os dados de forma eficiente (cache)
@st.cache_data
def load_data():
    """Carrega e limpa os dados do CSV."""
    try:
        # L√™ o arquivo dados_limpos.csv, que agora cont√©m 100 linhas
        df = pd.read_csv("dados_limpos.csv")
        # Mantemos a limpeza inicial: remover NaNs na vari√°vel alvo
        df_clean = df.dropna(subset=["SOLO_PCT"])
        return df_clean
    except FileNotFoundError:
        st.error("Erro: O arquivo 'dados_limpos.csv' n√£o foi encontrado. Por favor, certifique-se de que o script 'dados_simulados.py' foi executado para gerar este arquivo.")
        return pd.DataFrame() # Retorna um DataFrame vazio em caso de erro

# Decorador para treinar o modelo de forma eficiente (cache)
@st.cache_resource
def train_model(df_data):
    """Treina o modelo de Regress√£o Linear e retorna resultados."""
    if df_data.empty:
        return None, None, None, None, None, None

    # Vari√°veis alvo e preditoras 
    features = ['PH', 'NPK_N', 'NPK_P', 'NPK_K', 'LDR_MV']
    target_variable = 'SOLO_PCT'

    X = df_data[features]
    y = df_data[target_variable]

    # VALIDACAO ML: Checar se o dataset √© grande o suficiente
    if len(X) < 5:
        st.error(f"Erro de ML: Dataset com apenas {len(X)} linhas. √â necess√°rio no m√≠nimo 5 linhas para a divis√£o 80/20 est√°vel.")
        return None, None, None, None, None, None

    # Divis√£o em conjuntos de Treinamento e Teste (80/20) 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Treinamento
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Avalia√ß√£o das M√©tricas
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    return model, X, X_test, y_test, y_pred, {'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2}

# ================================================
# 1. Carregar os Dados e Definir Vari√°veis
# ================================================
df = load_data()

if df.empty:
    st.stop() # Para a execu√ß√£o se os dados n√£o puderem ser carregados

# Vari√°veis alvo e preditoras
target_variable = 'SOLO_PCT'
features = ['PH', 'NPK_N', 'NPK_P', 'NPK_K', 'LDR_MV']
numeric_columns_features = [col for col in df.columns.tolist() if col != target_variable]

# T√≠tulo do aplicativo
st.title('üî¨ Explora√ß√£o e Predi√ß√£o de Umidade do Solo (Agricultura 4.0)')
st.markdown("""
    Este dashboard integra a An√°lise Explorat√≥ria de Dados (EDA) dos seus sensores com um Modelo de Machine Learning (Regress√£o Linear)
    para prever a umidade do solo (`SOLO_PCT`).
""")

# Mostrar os primeiros registros
st.header('1. Vis√£o Geral dos Dados')
st.markdown(f"O DataFrame cont√©m **{df.shape[0]} linhas** e **{df.shape[1]} colunas** (1 vari√°vel alvo + {len(numeric_columns_features)} preditoras).")
st.dataframe(df.head())
st.subheader('Estat√≠sticas Descritivas')
st.dataframe(df.describe().T)

# ================================================
# 2. An√°lise de Correla√ß√£o (Fundamental para ML)
# ================================================
st.header('2. An√°lise de Correla√ß√£o')
st.markdown('A correla√ß√£o de Pearson √© crucial para entender quais sensores t√™m maior poder preditivo sobre a umidade do solo.')

# Mapa de calor de correla√ß√£o
st.subheader('üå°Ô∏è Mapa de Calor de Correla√ß√£o entre Todas as Vari√°veis')
corr = df.corr(numeric_only=True)
fig_heatmap, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5, ax=ax, cbar_kws={'label': 'Coeficiente de Correla√ß√£o'})
ax.set_title('Mapa de Calor de Correla√ß√£o de Pearson')
st.pyplot(fig_heatmap)

# Tabela de Correla√ß√£o com a Vari√°vel Alvo
st.subheader(f'Correla√ß√£o de Pearson com {target_variable}')
corr_target = corr[[target_variable]].sort_values(by=target_variable, ascending=False).drop(target_variable)
st.dataframe(corr_target)

# ================================================
# 3. Modelagem Preditiva (ML) - Avalia√ß√£o
# ================================================
st.header('3. Avalia√ß√£o do Modelo Preditivo (Regress√£o Linear)')
st.markdown("O modelo preditivo utiliza os sensores (`PH`, `NPK_N`, `NPK_P`, `NPK_K`, `LDR_MV`) para prever `SOLO_PCT`.")

# Treinar o Modelo
with st.spinner('Treinando o Modelo de Regress√£o Linear...'):
    model, X, X_test, y_test, y_pred, metrics = train_model(df)

if model is not None and metrics is not None:
    # 3.1. Avalia√ß√£o do Modelo
    st.subheader('üöÄ Desempenho do Modelo')
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("R¬≤ Score", f"{metrics['r2']:.4f}", help="Coeficiente de Determina√ß√£o. Pr√≥ximo de 1 indica alta precis√£o.")
    with col2:
        st.metric("RMSE", f"{metrics['rmse']:.4f}", help="Raiz do Erro Quadr√°tico M√©dio. Penaliza erros maiores.")
    with col3:
        st.metric("MAE", f"{metrics['mae']:.4f}", help="Erro Absoluto M√©dio. Erro m√©dio das previs√µes.")
    with col4:
        st.metric("MSE", f"{metrics['mse']:.4f}", help="Erro Quadr√°tico M√©dio.")

    st.markdown(f"""
    <div style="background-color: #e6f7ff; padding: 10px; border-radius: 5px; margin-top: 10px;">
    **An√°lise:** O valor de **R¬≤ ({metrics['r2']:.4f})** indica que o modelo de Regress√£o Linear explica uma boa parte da varia√ß√£o na umidade do solo.
    Para aumentar a precis√£o (melhorar o R¬≤), considere a inclus√£o de features n√£o-lineares ou a ado√ß√£o de modelos mais complexos (como Random Forest ou SVR).
    </div>
    """, unsafe_allow_html=True)

    # 3.2. Visualiza√ß√£o dos Res√≠duos
    st.subheader('An√°lise de Res√≠duos')
    resid_df = pd.DataFrame({'Real': y_test, 'Previsto': y_pred, 'Res√≠duo': y_test - y_pred})
    
    # Gr√°fico de Res√≠duos (Erro vs. Previs√£o)
    fig_resid = px.scatter(
        resid_df,
        x='Previsto',
        y='Res√≠duo',
        title='Res√≠duos do Modelo (Erro vs. Previs√£o)',
        labels={'Previsto': 'Umidade Prevista (%)', 'Res√≠duo': 'Res√≠duo (Real - Previsto)'},
        color_discrete_sequence=['#ff7f0e']
    )
    fig_resid.add_hline(y=0, line_dash="dash", line_color="red")
    st.plotly_chart(fig_resid, use_container_width=True)
    st.markdown("*Res√≠duos bem distribu√≠dos ao redor de zero sugerem que a Regress√£o Linear √© um bom ajuste para a rela√ß√£o entre as vari√°veis.*")
    
# ================================================
# 4. An√°lise Bivariada (Visualizando a Correla√ß√£o)
# ================================================
st.header('4. Rela√ß√£o Visual entre Sensores e Umidade do Solo')
st.markdown('Gr√°ficos de dispers√£o com linha de tend√™ncia (OLS) para visualizar as correla√ß√µes identificadas na Se√ß√£o 2.')

col_biv_1, col_biv_2 = st.columns(2)

for i, x_var in enumerate(numeric_columns_features):
    target_col = col_biv_1 if i % 2 == 0 else col_biv_2
    
    with target_col:
        st.write(f'**{target_variable} vs {x_var}**')
        
        # Gr√°fico de Dispers√£o com Linha de Tend√™ncia OLS
        fig = px.scatter(
            df,
            x=x_var,
            y=target_variable,
            title=f'{target_variable} vs {x_var}',
            trendline='ols', # OLS (Regress√£o Linear) para visualizar a correla√ß√£o
            trendline_color_override="#d62728",
            color=target_variable, # Colore pelo valor da pr√≥pria umidade do solo
            color_continuous_scale=px.colors.sequential.Viridis,
        )
        st.plotly_chart(fig, use_container_width=True)

# ================================================
# 5. An√°lise Univariada (Mantida)
# ================================================
st.header('5. An√°lise Univariada e Outliers')

st.subheader(f'üéØ Distribui√ß√£o da Vari√°vel Alvo: {target_variable} (%)')
fig_target = px.histogram(df, x=target_variable, nbins=30, 
                          title=f'Distribui√ß√£o de {target_variable}',
                          color_discrete_sequence=['#2a9d8f'])
st.plotly_chart(fig_target, use_container_width=True)

st.subheader('üìà Box Plots dos Sensores (Identifica√ß√£o de Outliers)')
# Box Plot para cada sensor
cols_box = st.columns(len(numeric_columns_features))
for i, col in enumerate(numeric_columns_features):
    with cols_box[i]:
        fig_box = px.box(df, y=col, points='suspectedoutliers', title=col)
        fig_box.update_layout(height=400)
        st.plotly_chart(fig_box, use_container_width=True)

# ================================================
# FIM
# ================================================
st.divider()
st.markdown("""
> **Conclus√£o (EDA/ML):** As an√°lises e o R¬≤ indicam que o modelo √© v√°lido para fazer previs√µes. O simulador (agora no painel 'Modelagem Preditiva') transforma essa an√°lise em uma a√ß√£o de manejo agr√≠cola, cumprindo o objetivo de transformar dados em decis√µes √°geis.
""")